{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8cb5e8a",
   "metadata": {},
   "source": [
    "# Chamfer Approximation\n",
    "\n",
    "In this notebook we attempt to approximate the chamfer similarity directly. First, we build an LSH forest for each document and query to find the closest matching vector before taking the dot product. Second, we use an LSH forest that encorporates multiple documents together and perform this same estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "783439b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "\n",
    "def chamfer(queries: np.ndarray, vectors: np.ndarray):\n",
    "        \"\"\"Takes two sets of vectors and calculates chamfer\"\"\"\n",
    "\n",
    "        # (n, m) matrix of all the pairwise dot products\n",
    "        dot_products = queries @ vectors.T\n",
    "\n",
    "        # sum the max value for each query (row)\n",
    "        chamfer = np.sum(np.max(dot_products, axis=1))\n",
    "        return chamfer\n",
    "\n",
    "# Quick test\n",
    "A = np.array([[1, 0]], dtype=float)\n",
    "B = np.array([[1, 0], [np.sqrt(.5), np.sqrt(.5)]], dtype=float)\n",
    "C = np.array([[1, 0], [0, 1], [np.sqrt(.1), np.sqrt(.9)], [np.sqrt(.5), np.sqrt(.5)]], dtype=float)\n",
    "\n",
    "assert chamfer(A, B) == pytest.approx(1.0)\n",
    "assert chamfer(B, A) == pytest.approx(1 + np.sqrt(.5))\n",
    "assert chamfer(B, C) == pytest.approx(2)\n",
    "assert chamfer(B, B) == pytest.approx(2)\n",
    "assert chamfer(C, C) == pytest.approx(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.590232849121094, 0)\n",
      "(3.535553455352783, 7)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m         results = forest.query(query, a, dist=distance)\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m document, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m                 idx, _ = result[\u001b[32m0\u001b[39m]\n\u001b[32m     60\u001b[39m                 matches[document, i] = forest.data[document][idx]\n\u001b[32m     61\u001b[39m sims = np.tensordot(matches, queries, axes=([\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m], [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]))\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "from shared.lsh_forest import LSHForest, MultiDocLSHForest, BitSamplingLSH\n",
    "\n",
    "n = 10                                  # number of documents\n",
    "q = 16                                  # vectors per query\n",
    "m = 32                                  # vectors per document\n",
    "d = 64                                  # dimension per vector\n",
    "l = 10                                  # trees per forest\n",
    "k = 10                                  # pivots to keep per node in tree\n",
    "km = 64                                 # max depth of each tree\n",
    "a = 15                                  # number of neighbors to retrieve per query\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "# Get normalized document and query vectors\n",
    "vectors = rng.normal(size=(n, m, d)).astype(np.float32)\n",
    "vectors /= np.linalg.norm(vectors, axis=-1, keepdims=True)\n",
    "\n",
    "queries = rng.normal(size=(q, d)).astype(np.float32)\n",
    "queries /= np.linalg.norm(queries, axis=-1, keepdims=True)\n",
    "\n",
    "distance = lambda a, b: -np.dot(a, b)\n",
    "\n",
    "\n",
    "# Build the forests\n",
    "single_doc_forests = [LSHForest(BitSamplingLSH(d), l, k, km) for _ in range(n)]\n",
    "for doc, forest in enumerate(single_doc_forests):\n",
    "        forest.batch_insert(vectors[doc])\n",
    "\n",
    "multi_doc_forest = MultiDocLSHForest(BitSamplingLSH(d), l, k, km)\n",
    "multi_doc_forest.batch_insert(vectors)\n",
    "\n",
    "\n",
    "# Baseline\n",
    "best = (0, 0)\n",
    "for document, doc_vecs in enumerate(vectors):\n",
    "        sim = chamfer(queries, doc_vecs)\n",
    "        if sim >= best[0]:\n",
    "                best = (float(sim), document)\n",
    "print(best)\n",
    "\n",
    "\n",
    "# Evaluate single-doc\n",
    "matches = np.empty((n, q, d), dtype=np.float32)\n",
    "for document, forest in enumerate(single_doc_forests):\n",
    "        for i, query in enumerate(queries):\n",
    "                idx = forest.query(query, a, dist=distance)[0][0]\n",
    "                matches[document, i] = forest.data[idx]\n",
    "sims = np.tensordot(matches, queries, axes=([1, 2], [0, 1]))\n",
    "best_doc = int(np.argmax(sims))\n",
    "best = (float(sims[best_doc]), best_doc)\n",
    "print(best)\n",
    "\n",
    "\n",
    "# Evaluate multi-doc\n",
    "matches.fill(0)\n",
    "for i, query in enumerate(queries):\n",
    "        results = multi_doc_forest.query(query, a, dist=distance)\n",
    "        for document, result in enumerate(results):\n",
    "                idx, _ = result[0]\n",
    "                matches[document, i] = multi_doc_forest.data[document][idx]\n",
    "sims = np.tensordot(matches, queries, axes=([1, 2], [0, 1]))\n",
    "best_doc = int(np.argmax(sims))\n",
    "best = (float(sims[best_doc]), best_doc)\n",
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc75026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test with many documents and varying hyperparameters\n",
    "# Some graphs of convergence would be nice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
