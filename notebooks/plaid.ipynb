{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26346109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from collections import defaultdict\n",
    "\n",
    "import ir_datasets\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92d14ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc5b4a9d3f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69872b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. DATA\n",
    "ds = load_dataset(\"ms_marco\", \"v2.1\", split=\"train[:2000]\")\n",
    "passages = [\" \".join(ex[\"passages\"][\"passage_text\"]) for ex in ds]\n",
    "queries  = ds[:6][\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578ae0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. ENCODER\n",
    "# Load tokenizer + encoder (MiniLM)\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encoder = AutoModel.from_pretrained(model_name).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fcd269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text(texts, max_len=64):\n",
    "    \"\"\"\n",
    "    Returns a list of *L_i × d* numpy arrays (one per input string),\n",
    "    **L_i excludes [CLS]/[SEP]** and embeddings are ℓ₂-normalised.\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    inp = tokenizer(\n",
    "        texts, padding=True, truncation=True,\n",
    "        return_tensors=\"pt\", max_length=max_len\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    emb = encoder(**inp).last_hidden_state            # (B, L, d)\n",
    "    mask = inp.attention_mask.bool()\n",
    "\n",
    "    out = []\n",
    "    for i in range(len(texts)):\n",
    "        # drop special-tokens, move to cpu → np, normalise\n",
    "        vecs = emb[i][mask[i]][1:-1].cpu().numpy()\n",
    "        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-8\n",
    "        out.append(vecs.astype(np.float32))\n",
    "\n",
    "    return out                              # list of (L_i, d) arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d11691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. OFFLINE INDEX BUILDING\n",
    "doc_vecs  = encode_text(passages[:1000])\n",
    "token_mat = np.vstack(doc_vecs)\n",
    "\n",
    "# §4.1 PLAID\n",
    "k = 256\n",
    "kmeans = MiniBatchKMeans(k, batch_size=2048, random_state=42)\n",
    "kmeans.fit(token_mat)\n",
    "centroids = kmeans.cluster_centers_.astype(np.float32)\n",
    "centroids /= np.linalg.norm(centroids, axis=1, keepdims=True)  # normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8f0af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inverted index: centroid_id → {doc_id}\n",
    "inv_index = defaultdict(set)\n",
    "offset = 0\n",
    "for doc_id, v in enumerate(doc_vecs):\n",
    "    c_ids = kmeans.predict(v)                        # (L_i,)\n",
    "    for cid in np.unique(c_ids):\n",
    "        inv_index[cid].add(doc_id)\n",
    "    doc_vecs[doc_id] = c_ids                         # keep as centroid-ids\n",
    "    offset += len(v)\n",
    "\n",
    "inv_index = {cid: np.fromiter(docs, dtype=np.int32)\n",
    "             for cid, docs in inv_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ba271a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. SEARCH COMPONENTS\n",
    "def centroid_scores(q_vec):\n",
    "    \"\"\"C · Qᵀ  →  (k, |q|)  as in Eq. 2 of the paper.\"\"\"\n",
    "    return centroids @ q_vec.T                       # float32\n",
    "\n",
    "def centroid_pruned_ids(S_cq, t_cs=0.45, nprobe=2):\n",
    "    \"\"\"\n",
    "    Stage-1 candidate generation (§4.1) + centroid pruning (§4.3).\n",
    "    *nprobe*  : #top-centroids per query-token.\n",
    "    *t_cs*    : pruning threshold.\n",
    "    returns   : unique doc ids (np.int32)\n",
    "    \"\"\"\n",
    "    topc = np.argpartition(S_cq, -nprobe, axis=0)[-nprobe:]    # (nprobe, |q|)\n",
    "    cand_docs = set()\n",
    "    for cid in np.unique(topc):\n",
    "        # prune whole centroid if its best score < t_cs (§3.4, Eq. 5)\n",
    "        if S_cq[cid].max() < t_cs:\n",
    "            continue\n",
    "        cand_docs.update(inv_index.get(cid, []))\n",
    "    return np.fromiter(cand_docs, dtype=np.int32)\n",
    "\n",
    "def centroid_interaction_score(S_cq, doc_cids):\n",
    "    \"\"\"\n",
    "    Stage-2/3 centroid interaction (§4.2, Eq. 3-4).\n",
    "    doc_cids : 1-D array of centroid ids for that document.\n",
    "    \"\"\"\n",
    "    doc_scores = S_cq[doc_cids]               # (len(doc), |q|)\n",
    "    return doc_scores.max(axis=0).sum()       # scalar\n",
    "\n",
    "def rank_documents(query, k_final=10, nprobe=2, t_cs=0.45, ndocs=256):\n",
    "    \"\"\"\n",
    "    Complete PLAID pipeline up to *centroid-only* ranking\n",
    "    (i.e. without residual decompression to keep code short).\n",
    "    \"\"\"\n",
    "    q_vec = encode_text(query)[0]                             # (|q|, d)\n",
    "    S_cq = centroid_scores(q_vec)                             # (k, |q|)\n",
    "    C1   = centroid_pruned_ids(S_cq, t_cs, nprobe)            # Stage-1/2\n",
    "    if len(C1) == 0:\n",
    "        return []\n",
    "\n",
    "    # Stage-3: centroid interaction on |C1| docs, keep top-ndocs\n",
    "    scores = np.array([\n",
    "        centroid_interaction_score(S_cq, doc_vecs[did]) for did in C1\n",
    "    ], dtype=np.float32)\n",
    "    n_keep = min(ndocs, len(scores))              # <-- NEW\n",
    "    if n_keep == 0:\n",
    "        return []                                 # (shouldn't happen, but safe)\n",
    "    top_idx   = np.argpartition(scores, -n_keep)[-n_keep:]\n",
    "    top_nd    = C1[top_idx]\n",
    "\n",
    "    top_scores = [(did, scores[i]) for i, did in zip(top_idx, top_nd)]\n",
    "    top_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return top_scores[:k_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cceaea1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: )what was the immediate impact of the success of the manhattan project?\n",
      "\n",
      "Top 5 passages\n",
      " 1. (doc#971) Louis Racine. Louis Racine (born November 6, 1692, Paris; died January 29, 1763, Paris) was a French poet of the Age of  …  [5.190]\n",
      " 2. (doc#976) introDUCtion: tHe BeneFits oF an eFFeCtive Corporate internal investigation. Corporations are being scrutinized today as …  [5.106]\n",
      " 3. (doc#26) My husband and I stayed at the Residence Inn in Shelton, CT for 3 months following a kitchen fire in our house. This cou …  [5.102]\n",
      " 4. (doc#0) The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as sci …  [5.094]\n",
      " 5. (doc#936) (CNN)Biggest Loser host and fitness trainer Bob Harper said he is thankful to be alive after suffering a mid-February he …  [4.956]\n"
     ]
    }
   ],
   "source": [
    "hits = rank_documents(queries[0], k_final=5)\n",
    "print(\"\\nQuery:\", queries[0])\n",
    "print(\"\\nTop 5 passages\")\n",
    "for rank, (pid, score) in enumerate(hits, 1):\n",
    "    print(f\"{rank:>2}. (doc#{pid}) {passages[pid][:120]} …  [{score:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369c51b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Load and limit MS MARCO-dev qrels\n",
    "# -----------------------------\n",
    "msmarco_dev = ir_datasets.load(\"msmarco-passage/dev\")\n",
    "\n",
    "qrels = defaultdict(set)\n",
    "query_texts = {}\n",
    "doc_texts = {}\n",
    "count = 0\n",
    "max_qrels = 10000\n",
    "\n",
    "# Load only up to 500 relevant qrels\n",
    "for qrel in msmarco_dev.qrels_iter():\n",
    "    if qrel.relevance > 0:\n",
    "        qid, did = qrel.query_id, qrel.doc_id\n",
    "        qrels[qid].add(did)\n",
    "        if qid not in query_texts:\n",
    "            query_texts[qid] = None  # placeholder\n",
    "        if did not in doc_texts:\n",
    "            doc_texts[did] = None  # placeholder\n",
    "        count += 1\n",
    "        if count >= max_qrels:\n",
    "            break\n",
    "\n",
    "# Now fill in the actual query and document texts for the limited set\n",
    "for q in msmarco_dev.queries_iter():\n",
    "    if q.query_id in query_texts:\n",
    "        query_texts[q.query_id] = q.text\n",
    "\n",
    "for d in msmarco_dev.docs_iter():\n",
    "    if d.doc_id in doc_texts:\n",
    "        doc_texts[d.doc_id] = d.text\n",
    "\n",
    "# crude reverse map text → doc_id\n",
    "text2id = {v.strip(): k for k, v in doc_texts.items() if v is not None}\n",
    "\n",
    "# -- NEW: create passages and id maps ---------------------------------------\n",
    "ms_ids   = np.array(sorted(doc_texts))                # external ids\n",
    "passages = [doc_texts[did] for did in ms_ids]         # aligned texts\n",
    "\n",
    "# 1. OFFLINE INDEX -----------------------------------------------------------\n",
    "doc_vecs  = encode_text(passages)                     # list of (L_i, d)\n",
    "token_mat = np.vstack(doc_vecs)\n",
    "\n",
    "kmeans = MiniBatchKMeans(256, batch_size=2048, random_state=42).fit(token_mat)\n",
    "centroids = kmeans.cluster_centers_.astype(np.float32)\n",
    "centroids /= np.linalg.norm(centroids, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "inv_index = defaultdict(set)\n",
    "for internal_id, v in enumerate(doc_vecs):\n",
    "    c_ids = kmeans.predict(v)\n",
    "    for cid in np.unique(c_ids):\n",
    "        inv_index[cid].add(internal_id)\n",
    "    doc_vecs[internal_id] = c_ids\n",
    "\n",
    "inv_index = {cid: np.fromiter(docs, dtype=np.int32) for cid, docs in inv_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a90933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9529/9529 [08:35<00:00, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluated 9529 queries\n",
      "MRR@10   = 0.2997\n",
      "Recall@100 = 0.7854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2.  Scoring & metrics\n",
    "# -----------------------------\n",
    "K_MRR, K_REC = 10, 100\n",
    "tot_mrr = tot_rec = n_eval = 0\n",
    "\n",
    "for qid, qtext in tqdm(query_texts.items(), total=len(query_texts)):\n",
    "    top = rank_documents(qtext, k_final=K_REC, nprobe=2, t_cs=0.45, ndocs=1024)\n",
    "    our_ids = [ms_ids[pid] for pid, _ in top]         # <-- single guaranteed map\n",
    "\n",
    "    rels = qrels[qid]\n",
    "    if not rels:\n",
    "        continue\n",
    "\n",
    "    # MRR@10\n",
    "    first_hit = next((i for i, did in enumerate(our_ids[:K_MRR]) if did in rels), None)\n",
    "    tot_mrr  += 1.0 / (first_hit + 1) if first_hit is not None else 0.0\n",
    "\n",
    "    # Recall@100\n",
    "    tot_rec += sum(did in rels for did in our_ids) / len(rels)\n",
    "    n_eval  += 1\n",
    "\n",
    "print(f\"\\nEvaluated {n_eval} queries\")\n",
    "print(f\"MRR@{K_MRR}   = {tot_mrr / n_eval:.4f}\")\n",
    "print(f\"Recall@{K_REC} = {tot_rec / n_eval:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba3188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f383a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4d2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9d806-067b-47dd-9ded-fc9c3aa87a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
